col=c("red","green3","purple"), lwd=2, lty=c(1,2,3))
### 6. Plot MAE curves (with OLS & QuantReg baselines)
# Prediction MAE for OLS & QuantReg
mae_ols <- mean(abs(y - predict(ols_fit)))
mae_rq  <- mean(abs(y - predict(rq_fit)))
# Parameter MAE for OLS & QuantReg
mae_params_ols <- mean(abs(ols_coef - beta_true))
mae_params_rq  <- mean(abs(rq_coef - beta_true))
par(mfrow=c(2,1))
# Prediction MAE
plot(1:max_iter, MAE.loss, col="red", type="l", lwd=2,
main="Prediction MAE across iterations",
xlab="Iteration", ylab="Prediction MAE")
abline(h=mae_ols, col="green3", lwd=2, lty=2)
abline(h=mae_rq, col="purple", lwd=2, lty=3)
legend("topright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("red","green3","purple"), lty=c(1,2,3), lwd=2)
# Parameter MAE
plot(1:max_iter, MAE.params, col="blue", type="l", lwd=2,
main="Parameter MAE across iterations",
xlab="Iteration", ylab="Parameter MAE",
ylim = c(0, max(MAE.params, mae_params_ols, mae_params_rq)*1.1))
abline(h=mae_params_ols, col="green3", lwd=2, lty=2)
abline(h=mae_params_rq, col="purple", lwd=2, lty=3)
legend("topright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("blue","green3","purple"), lty=c(1,2,3), lwd=2)
set.seed(123)
library(matrixStats)
library(quantreg)
### 1. Generate synthetic regression dataset with outliers
n <- 1e3   # samples
p <- 2     # features
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X.outliers <- matrix(rnorm(n/20 * (p-1), sd = 5), n/20, (p-1))  # outliers
X <- rbind(X, X.outliers)
X <- cbind(1,X)
beta_true <- c(2,5)
n <- 1.2 * n
rows <- sample(1:nrow(X), n/2, replace = FALSE)
X.normal <- X[rows, ]
X.out <- X[-rows, ]
y.normal <- X.normal %*% beta_true + rnorm(nrow(X.normal), sd = 5)
y.out <- X.out %*% beta_true + rnorm(nrow(X.out), sd = 25)
y <- c(y.normal, y.out)
X <- rbind(X.normal, X.out)
n <- nrow(X)
x <- X[,2]
## Visualize
plot(X[,2], y,
main = "Generated Data with Outliers",
xlab = "X", ylab = "y",
pch = 19, col = ifelse(1:n <= nrow(X.normal), "blue", "red"))
legend("bottomright", legend = c("Normal Data", "Outliers"),
col = c("blue", "red"), pch = 19)
### 2. LAD–CD Optimization
max_iter <- 100
a <- numeric(max_iter); b <- numeric(max_iter)
a_curr <- 20; b_curr <- 20
MAE.loss <- numeric(max_iter); MAE.params <- numeric(max_iter)
for(i in 1:max_iter){
z <- y - a_curr
z.bar <- z/x
b_curr <- weightedMedian(z.bar, abs(x))
b[i] <- b_curr
w <- y - b_curr * x
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - b_curr*x))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
cat("True params:", beta_true, "\n")
cat("LAD-CD params:", c(a_curr, b_curr), "\n")
### 3. OLS baseline
ols_fit <- lm(y ~ x)
ols_coef <- coef(ols_fit)
cat("OLS params:", ols_coef, "\n")
### 4. QuantReg baseline
rq_fit <- rq(y ~ x, method = "br")
rq_coef <- coef(rq_fit)
cat("QuantReg params:", rq_coef, "\n")
### 5. Visualise fits
pdf("Plots/EMLAD_ModelFit_Outliers.pdf", width=8, height=6)
par(mfrow=c(1,1))
plot(x, y, pch=19, col="black",
main="Fitted Lines under Outliers",
xlab="X", ylab="y")
abline(a=a_curr, b=b_curr, col="red", lwd=2)         # LAD-CD
abline(ols_coef, col="green3", lwd=2, lty=2)         # OLS
abline(rq_coef, col="purple", lwd=3, lty=4)          # QuantReg
legend("bottomright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("red","green3","purple"), lwd=2, lty=c(1,2,3))
dev.off()
### 6. Plot MAE curves (with OLS & QuantReg baselines)
# Prediction MAE for OLS & QuantReg
mae_ols <- mean(abs(y - predict(ols_fit)))
mae_rq  <- mean(abs(y - predict(rq_fit)))
# Parameter MAE for OLS & QuantReg
mae_params_ols <- mean(abs(ols_coef - beta_true))
mae_params_rq  <- mean(abs(rq_coef - beta_true))
pdf("Plots/MAE_params_and_loss_Outliers.pdf", width=8, height=10)
par(mfrow=c(2,1))
# Prediction MAE
plot(1:max_iter, MAE.loss, col="red", type="l", lwd=2,
main="Prediction MAE across iterations",
xlab="Iteration", ylab="Prediction MAE")
abline(h=mae_ols, col="green3", lwd=2, lty=2)
abline(h=mae_rq, col="purple", lwd=2, lty=3)
legend("topright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("red","green3","purple"), lty=c(1,2,3), lwd=2)
# Parameter MAE
plot(1:max_iter, MAE.params, col="blue", type="l", lwd=2,
main="Parameter MAE across iterations",
xlab="Iteration", ylab="Parameter MAE",
ylim = c(0, max(MAE.params, mae_params_ols, mae_params_rq)*1.1))
abline(h=mae_params_ols, col="green3", lwd=2, lty=2)
abline(h=mae_params_rq, col="purple", lwd=2, lty=3)
legend("topright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("blue","green3","purple"), lty=c(1,2,3), lwd=2)
dev.off()
set.seed(123)
library(matrixStats)
library(quantreg)
### 1. Generate synthetic regression dataset with outliers
n <- 1e3   # samples
p <- 2     # features
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X.outliers <- matrix(rnorm(n/20 * (p-1), sd = 5), n/20, (p-1))  # outliers
X <- rbind(X, X.outliers)
X <- cbind(1,X)
beta_true <- c(2,5)
n <- 1.2 * n
rows <- sample(1:nrow(X), n/2, replace = FALSE)
X.normal <- X[rows, ]
X.out <- X[-rows, ]
y.normal <- X.normal %*% beta_true + rnorm(nrow(X.normal), sd = 5)
y.out <- X.out %*% beta_true + rnorm(nrow(X.out), sd = 25)
y <- c(y.normal, y.out)
X <- rbind(X.normal, X.out)
n <- nrow(X)
x <- X[,2]
## Visualize
par(mfrow=c(1,1))
plot(X[,2], y,
main = "Generated Data with Outliers",
xlab = "X", ylab = "y",
pch = 19, col = ifelse(1:n <= nrow(X.normal), "blue", "red"))
legend("bottomright", legend = c("Normal Data", "Outliers"),
col = c("blue", "red"), pch = 19)
### 2. LAD–CD Optimization
max_iter <- 100
a <- numeric(max_iter); b <- numeric(max_iter)
a_curr <- 20; b_curr <- 20
MAE.loss <- numeric(max_iter); MAE.params <- numeric(max_iter)
for(i in 1:max_iter){
z <- y - a_curr
z.bar <- z/x
b_curr <- weightedMedian(z.bar, abs(x))
b[i] <- b_curr
w <- y - b_curr * x
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - b_curr*x))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
cat("True params:", beta_true, "\n")
cat("LAD-CD params:", c(a_curr, b_curr), "\n")
### 3. OLS baseline
ols_fit <- lm(y ~ x)
ols_coef <- coef(ols_fit)
cat("OLS params:", ols_coef, "\n")
### 4. QuantReg baseline
rq_fit <- rq(y ~ x, method = "br")
rq_coef <- coef(rq_fit)
cat("QuantReg params:", rq_coef, "\n")
### 5. Visualise fits
pdf("Plots/EMLAD_ModelFit_Outliers.pdf", width=8, height=6)
par(mfrow=c(1,1))
plot(x, y, pch=19, col="black",
main="Fitted Lines under Outliers",
xlab="X", ylab="y")
abline(a=a_curr, b=b_curr, col="red", lwd=2)         # LAD-CD
abline(ols_coef, col="green3", lwd=2, lty=2)         # OLS
abline(rq_coef, col="purple", lwd=3, lty=4)          # QuantReg
legend("bottomright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("red","green3","purple"), lwd=2, lty=c(1,2,3))
dev.off()
### 6. Plot MAE curves (with OLS & QuantReg baselines)
# Prediction MAE for OLS & QuantReg
mae_ols <- mean(abs(y - predict(ols_fit)))
mae_rq  <- mean(abs(y - predict(rq_fit)))
# Parameter MAE for OLS & QuantReg
mae_params_ols <- mean(abs(ols_coef - beta_true))
mae_params_rq  <- mean(abs(rq_coef - beta_true))
pdf("Plots/MAE_params_and_loss_Outliers.pdf", width=8, height=10)
par(mfrow=c(2,1))
# Prediction MAE
plot(1:max_iter, MAE.loss, col="red", type="l", lwd=2,
main="Prediction MAE across iterations",
xlab="Iteration", ylab="Prediction MAE")
abline(h=mae_ols, col="green3", lwd=2, lty=2)
abline(h=mae_rq, col="purple", lwd=2, lty=3)
legend("topright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("red","green3","purple"), lty=c(1,2,3), lwd=2)
# Parameter MAE
plot(1:max_iter, MAE.params, col="blue", type="l", lwd=2,
main="Parameter MAE across iterations",
xlab="Iteration", ylab="Parameter MAE",
ylim = c(0, max(MAE.params, mae_params_ols, mae_params_rq)*1.1))
abline(h=mae_params_ols, col="green3", lwd=2, lty=2)
abline(h=mae_params_rq, col="purple", lwd=2, lty=3)
legend("topright", legend=c("LAD-CD","OLS","QuantReg"),
col=c("blue","green3","purple"), lty=c(1,2,3), lwd=2)
dev.off()
n <- 1000
p <- 1200
## Generate data
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X <- cbind(1, X)
beta_true <- c(2, 1:(p-1))
y <- as.vector(X %*% beta_true + rnorm(n, sd = 1))
## --------------------------
## LAD Coordinate Descent
## --------------------------
a <- numeric(max_iter)
b <- matrix(0, nrow = max_iter, ncol = p-1)
a_curr <- 1
b_curr <- rep(1, p-1)
MAE.loss <- numeric(max_iter)
MAE.params <- numeric(max_iter)
for (i in 1:max_iter) {
for (j in 1:(p-1)) {
x.j <- X[, 1+j]
X.rest <- X[, -c(1, 1+j)]
z <- y - a_curr - X.rest %*% b_curr[-j]
z.bar <- z / x.j
b_curr[j] <- weightedMedian(z.bar, abs(x.j))
b[i, ] <- b_curr
}
w <- y - X[, -1] %*% b_curr
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - X[, -1] %*% b_curr))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
res_cd <- list(
beta = c(a_curr, b_curr),
MAE.loss = MAE.loss,
MAE.params = MAE.params
)
max_iter <- 100
## Generate data
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X <- cbind(1, X)
beta_true <- c(2, 1:(p-1))
y <- as.vector(X %*% beta_true + rnorm(n, sd = 1))
## --------------------------
## LAD Coordinate Descent
## --------------------------
a <- numeric(max_iter)
b <- matrix(0, nrow = max_iter, ncol = p-1)
a_curr <- 1
b_curr <- rep(1, p-1)
MAE.loss <- numeric(max_iter)
MAE.params <- numeric(max_iter)
for (i in 1:max_iter) {
for (j in 1:(p-1)) {
x.j <- X[, 1+j]
X.rest <- X[, -c(1, 1+j)]
z <- y - a_curr - X.rest %*% b_curr[-j]
z.bar <- z / x.j
b_curr[j] <- weightedMedian(z.bar, abs(x.j))
b[i, ] <- b_curr
}
w <- y - X[, -1] %*% b_curr
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - X[, -1] %*% b_curr))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
## --------------------------
## LAD Coordinate Descent
## --------------------------
# Ridge init (use if p >= n or ill-conditioned)
init_ridge <- function(X, y, lambda = 1e-3) {
# glmnet expects x without intercept; return vector including intercept
library(glmnet)
x_no_intercept <- X[ , -1, drop = FALSE]
fit <- glmnet(x_no_intercept, y, alpha = 0, lambda = lambda, standardize = TRUE)
# glmnet returns coefficients with intercept
as.numeric(c(fit$a0, as.vector(as.matrix(fit$beta))))
}
init <- init_ridge(X, y, lambda = 1e-3)
install.packages("glmnet")
library(glmnet)
n <- 1000
p <- 1200
max_iter <- 100
## Generate data
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X <- cbind(1, X)
beta_true <- c(2, 1:(p-1))
y <- as.vector(X %*% beta_true + rnorm(n, sd = 1))
## --------------------------
## LAD Coordinate Descent
## --------------------------
# Ridge init (use if p >= n or ill-conditioned)
init_ridge <- function(X, y, lambda = 1e-3) {
# glmnet expects x without intercept; return vector including intercept
x_no_intercept <- X[ , -1, drop = FALSE]
fit <- glmnet(x_no_intercept, y, alpha = 0, lambda = lambda, standardize = TRUE)
# glmnet returns coefficients with intercept
as.numeric(c(fit$a0, as.vector(as.matrix(fit$beta))))
}
a <- numeric(max_iter)
b <- matrix(0, nrow = max_iter, ncol = p-1)
init <- init_ridge(X, y, lambda = 1e-3)
a_curr <- init[1]
b_curr <- init[-1]
MAE.loss <- numeric(max_iter)
MAE.params <- numeric(max_iter)
for (i in 1:max_iter) {
for (j in 1:(p-1)) {
x.j <- X[, 1+j]
X.rest <- X[, -c(1, 1+j)]
z <- y - a_curr - X.rest %*% b_curr[-j]
z.bar <- z / x.j
b_curr[j] <- weightedMedian(z.bar, abs(x.j))
b[i, ] <- b_curr
}
w <- y - X[, -1] %*% b_curr
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - X[, -1] %*% b_curr))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
## Helper function to plot LAD-CD convergence with QuantReg baseline
plot_with_baseline <- function(cd_loss, rq_val, col_cd, col_rq,
main, ylab="MAE") {
plot(1:length(cd_loss), cd_loss, type="l", col=col_cd, lwd=2,
xlab="Iteration", ylab=ylab, main=main,
ylim = c(0, max(cd_loss, na.rm=TRUE)*1.1))
if (!is.na(rq_val)) {
abline(h=rq_val, col=col_rq, lwd=2, lty=2)
legend("topright", legend=c("LAD-CD", "QuantReg"),
col=c(col_cd, col_rq), lty=c(1,2), lwd=2)
} else {
legend("bottomright", legend=c("LAD-CD",
"No result for RegQuant"),
col=c(col_cd, col_rq), lty=1, lwd=2)
}
}
par(mfrow=c(1,2))
plot_with_baseline(MAE.loss, NA,
"blue", "darkgreen", "Prediction MAE Loss (p=1200)")
plot_with_baseline(MAE.params, NA,
"red", "darkgreen", "Parameter MAE Loss (p=1200)")
library(glmnet)
library(MASS)
n <- 1000
p <- 1200
max_iter <- 100
## Generate data
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X <- cbind(1, X)
beta_true <- c(2, 1:(p-1))
y <- as.vector(X %*% beta_true + rnorm(n, sd = 1))
## --------------------------
## LAD Coordinate Descent
## --------------------------
# Ridge init (use if p >= n or ill-conditioned)
init_rlm <- function(X, y) {
df <- data.frame(y = y, X[ , -1, drop=FALSE])
colnames(df)[-1] <- paste0("V", 1:(ncol(X)-1))
form <- as.formula(paste("y ~", paste(colnames(df)[-1], collapse = " + ")))
fit <- rlm(form, data = df, method = "M")
coef(fit)  # intercept + slopes
}
a <- numeric(max_iter)
b <- matrix(0, nrow = max_iter, ncol = p-1)
init <- init_rlm(X, y, lambda = 1e-3)
init <- init_rlm(X, y)
b_curr <- init[-1]
library(glmnet)
library(MASS)
n <- 1000
p <- 1200
max_iter <- 100
## Generate data
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X <- cbind(1, X)
beta_true <- c(2, 1:(p-1))
y <- as.vector(X %*% beta_true + rnorm(n, sd = 1))
## --------------------------
## LAD Coordinate Descent
## --------------------------
# Ridge init (use if p >= n or ill-conditioned)
init_ridge <- function(X, y, lambda = 1.0) {
# X is with intercept column as first column (col of 1s).
# We will center columns (except intercept) so intercept is unpenalized.
stopifnot(is.matrix(X))
p <- ncol(X)
# separate intercept
intercept_col <- X[,1, drop=FALSE]
Xno <- X[, -1, drop = FALSE]
# center predictors and response
x_means <- colMeans(Xno)
Xc <- sweep(Xno, 2, x_means, "-")
y_mean <- mean(y)
yc <- y - y_mean
# closed form (ridge): beta_without_intercept = (Xc'Xc + lambda I)^{-1} Xc' yc
XtX <- crossprod(Xc)           # (p-1)x(p-1)
ridge_mat <- XtX + lambda * diag(ncol(Xc))
beta_no_intercept <- solve(ridge_mat, crossprod(Xc, yc))
intercept <- y_mean - sum(beta_no_intercept * x_means)
beta_full <- c(intercept, as.numeric(beta_no_intercept))
return(beta_full)
}
a <- numeric(max_iter)
b <- matrix(0, nrow = max_iter, ncol = p-1)
init <- init_ridge(X, y, lambda = 1e-3)
a_curr <- init[1]
b_curr <- init[-1]
MAE.loss <- numeric(max_iter)
MAE.params <- numeric(max_iter)
for (i in 1:max_iter) {
for (j in 1:(p-1)) {
x.j <- X[, 1+j]
X.rest <- X[, -c(1, 1+j)]
z <- y - a_curr - X.rest %*% b_curr[-j]
z.bar <- z / x.j
b_curr[j] <- weightedMedian(z.bar, abs(x.j))
b[i, ] <- b_curr
}
w <- y - X[, -1] %*% b_curr
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - X[, -1] %*% b_curr))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
res_cd <- list(
beta = c(a_curr, b_curr),
MAE.loss = MAE.loss,
MAE.params = MAE.params
)
par(mfrow=c(1,2))
plot_with_baseline(MAE.loss, NA,
"blue", "darkgreen", "Prediction MAE Loss (p=1200)")
plot_with_baseline(MAE.params, NA,
"red", "darkgreen", "Parameter MAE Loss (p=1200)")
library(matrixStats)
library(glmnet)
library(MASS)
library(matrixStats)
n <- 1000
p <- 1200
max_iter <- 100
## Generate data
X <- matrix(rnorm(n * (p-1)), n, (p-1))
X <- cbind(1, X)
beta_true <- c(2, 1:(p-1))
y <- as.vector(X %*% beta_true + rnorm(n, sd = 1))
## --------------------------
## LAD Coordinate Descent
## --------------------------
# Function to compute marginal LAD coefficients
init_marginal_LAD <- function(X, y) {
n <- nrow(X)
p <- ncol(X)
beta_init <- numeric(p)
# intercept = median(y)
beta_init[1] <- median(y)
# slopes via univariate LAD
for (j in 2:p) {
xj <- X[, j]
z  <- (y - beta_init[1]) / xj    # candidate slopes
w  <- abs(xj)                    # weights
beta_init[j] <- weightedMedian(z, w)
}
return(beta_init)
}
a <- numeric(max_iter)
b <- matrix(0, nrow = max_iter, ncol = p-1)
init <- init_marginal_LAD(X, y)
a_curr <- init[1]
b_curr <- init[-1]
MAE.loss <- numeric(max_iter)
MAE.params <- numeric(max_iter)
for (i in 1:max_iter) {
for (j in 1:(p-1)) {
x.j <- X[, 1+j]
X.rest <- X[, -c(1, 1+j)]
z <- y - a_curr - X.rest %*% b_curr[-j]
z.bar <- z / x.j
b_curr[j] <- weightedMedian(z.bar, abs(x.j))
b[i, ] <- b_curr
}
w <- y - X[, -1] %*% b_curr
a_curr <- median(w)
a[i] <- a_curr
MAE.loss[i] <- mean(abs(y - a_curr - X[, -1] %*% b_curr))
MAE.params[i] <- mean(abs(c(a_curr, b_curr) - beta_true))
}
res_cd <- list(
beta = c(a_curr, b_curr),
MAE.loss = MAE.loss,
MAE.params = MAE.params
)
par(mfrow=c(1,2))
plot_with_baseline(MAE.loss, NA,
"blue", "darkgreen", "Prediction MAE Loss (p=1200)")
plot_with_baseline(MAE.params, NA,
"red", "darkgreen", "Parameter MAE Loss (p=1200)")
